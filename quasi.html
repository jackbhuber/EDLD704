<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.38">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>EDLD704: Methods and Instruments for Data Collection - Quasi-Experimental Design</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./surveys.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">EDLD704: Methods and Instruments for Data Collection</span>
  </a>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">Quasi-Experimental Design</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Description of the Course</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">Questions, Methods, and Data</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Quantitative Methods</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./surveys.html" class="sidebar-item-text sidebar-link">Surveys</a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./quasi.html" class="sidebar-item-text sidebar-link active">Quasi-Experimental Design</a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <span class="sidebar-item-text sidebar-link text-start">Qualitative Methods</span>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#to-evaluate-a-program" id="toc-to-evaluate-a-program" class="nav-link active" data-scroll-target="#to-evaluate-a-program">To evaluate a program</a></li>
  <li><a href="#what-counts-as-convincing-evidence" id="toc-what-counts-as-convincing-evidence" class="nav-link" data-scroll-target="#what-counts-as-convincing-evidence">What counts as convincing evidence?</a></li>
  <li><a href="#threats-to-validity" id="toc-threats-to-validity" class="nav-link" data-scroll-target="#threats-to-validity">Threats to validity</a></li>
  <li><a href="#experimental-design-with-random-assignment" id="toc-experimental-design-with-random-assignment" class="nav-link" data-scroll-target="#experimental-design-with-random-assignment">Experimental design with random assignment</a></li>
  <li><a href="#quasi-experimental-designs" id="toc-quasi-experimental-designs" class="nav-link" data-scroll-target="#quasi-experimental-designs">Quasi-experimental designs</a>
  <ul class="collapse">
  <li><a href="#the-nonequivalent-control-group-design" id="toc-the-nonequivalent-control-group-design" class="nav-link" data-scroll-target="#the-nonequivalent-control-group-design">The Nonequivalent Control Group Design</a></li>
  </ul></li>
  <li><a href="#how-to-do-a-program-evaluation-using-a-quasi-experimental-design" id="toc-how-to-do-a-program-evaluation-using-a-quasi-experimental-design" class="nav-link" data-scroll-target="#how-to-do-a-program-evaluation-using-a-quasi-experimental-design">How to do a program evaluation using a quasi-experimental design</a></li>
  <li><a href="#recommended-further-reading" id="toc-recommended-further-reading" class="nav-link" data-scroll-target="#recommended-further-reading">Recommended further reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">Quasi-Experimental Design</h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<hr>
<p>Required reading:</p>
<ul>
<li><p>Chapter 4 (pp.&nbsp;56-61) in <span class="citation" data-cites="Burkholder">Burkholder et al. (<a href="references.html#ref-Burkholder" role="doc-biblioref">2020</a>)</span></p></li>
<li><p>Chapter 17 in <span class="citation" data-cites="Burkholder">Burkholder et al. (<a href="references.html#ref-Burkholder" role="doc-biblioref">2020</a>)</span></p></li>
</ul>
<hr>
<section id="to-evaluate-a-program" class="level2">
<h2 class="anchored" data-anchor-id="to-evaluate-a-program">To evaluate a program</h2>
<p>In education, we often design programs to improve instruction or aspects of schooling to improve outcomes for students. Most programs cost time, money, or other limited resources.</p>
<p>Consider, for the moment, one program that perhaps you have led, implemented, inherited and maintained, or otherwise invested your attention into yourself. Inevitably the question will arise: How well is this program “working”? Do the benefits it yields outweigh the costs? These questions depend on a fundamental question which is our focus for this module:</p>
<p>What counts as evidence? How can we know?</p>
<p>When I worked in districts as the assessment director, questions of program evaluation came up many times. In many cases the originating question was, “Let’s look at the data!” and in most cases that really meant, “Some students were part of a program. Let’s look at <em>their</em> data.”</p>
<p>Often the data were scores on a common assessment of student achievement. This included districtwide assessments like DIBELS, STAR, or MAP, or the annual state assessment such as the WASL, the MSP, or the SBA. Students were often selected for a program on the basis of low pretest scores (“Level 1s” and “Level 2s”) and the outcome measure was often the same assessment given in a later testing window.</p>
<p>Favorable outcomes for this group then counted as sufficient evidence of program efficacy, and more often than not, the <em>de facto</em> evaluator was the person most invested in the program and bent on seeing it continue.</p>
<p>Seldom did it occur to people (or if it did, nobody said anything) what would likely have otherwise happened to these students without experiencing the program. Were they <em>better off</em> experiencing this program than the likely alternative? What about very similar students who could have experienced this program but for whatever reason didn’t? What were their outcomes?</p>
<p>This whole discussion rests on philosophical assumptions (or commitments, or investments) that we can more or less systematically <strong>cause</strong> better student outcomes and more or less measure this causation. Put another way, it’s common to justify the merit or importance of one’s work with <strong>causal inferences</strong> that the work <strong>makes a difference</strong>.</p>
<p>Questions about how, when, on whom we collect, organize, and analyze evidence to make causal inferences are questions of <strong>research</strong> <strong>design</strong>. Design is the framework for a study.</p>
</section>
<section id="what-counts-as-convincing-evidence" class="level2">
<h2 class="anchored" data-anchor-id="what-counts-as-convincing-evidence">What counts as convincing evidence?</h2>
<p>Let’s begin by consider a hypothetical scenario of elementary reading, depicted in Table 1. Fifty third grade students score below grade level (40th percentile) on their spring SBA English Language Arts assessment. All of the students return to the same school in the fall for their fourth grade year. Half are assigned to the Innovative Reading Program while the other 25 receive Tier 1 grade level instruction. In the spring, all 50 students take the Grade 4 SBA ELA assessment.</p>
<p><strong>Table 1</strong></p>
<p><strong><em>Standardized Reading Achievement by Reading Program Placement</em></strong></p>
<table class="table">
<colgroup>
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 19%">
<col style="width: 22%">
<col style="width: 19%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">N</th>
<th style="text-align: center;">Pretest</th>
<th style="text-align: center;">% low income</th>
<th style="text-align: center;">Placement</th>
<th style="text-align: center;">Posttest</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">24</td>
<td style="text-align: center;">2398 (40th)</td>
<td style="text-align: center;">51</td>
<td style="text-align: center;">Tier 1 Grade Level Instruction</td>
<td style="text-align: center;">2474 (50th)</td>
</tr>
<tr class="even">
<td style="text-align: center;">26</td>
<td style="text-align: center;">2401 (40th)</td>
<td style="text-align: center;">49</td>
<td style="text-align: center;">Innovative Reading Program</td>
<td style="text-align: center;">2523 (70th)</td>
</tr>
</tbody>
</table>
<p>When the scores become available shortly, they bring good news. All 50 students meet the Level 3 proficiency standard. The average scores of the 25 students in the Tier 1 grade level classroom score is 2474 (roughly the 50th percentile). They’ve all caught up to grade level. The results of the students receiving the Innovative Reading Program are even better: their average SBA score is 2523, the 70th percentile for fourth grade. Proponents of the program rejoice. “Not so fast!” cry the program critics.</p>
</section>
<section id="threats-to-validity" class="level2">
<h2 class="anchored" data-anchor-id="threats-to-validity">Threats to validity</h2>
<p>Here are their objections:</p>
<p>“Of course their scores increased! <u>Reading was a district and school focus. Everyone was talking about it last year. It was in the air</u>.” This threat to validity, an alternative explanation for the outcome of the experimental group apart from the treatment itself, is called <strong>history</strong>.</p>
<p>“Of course their scores increased! <u>Kids grow and mature anyway. Studies have shown gains in scores for kids with no formal schooling at all</u>.” This threat to validity, an alternative explanation for the outcome of the experimental group apart from the treatment itself, is called <strong>maturation</strong>.</p>
<p>“Of course their scores increased! <u>Having already taken the third grade SBA test, they knew what to expect of the test. They knew how to take it</u>.” This threat to validity, an alternative explanation for the outcome of the experimental group apart from the treatment itself, is called <strong>testing</strong>.</p>
<p>“Of course their scores increased! <u>The fourth grade SBA was easier for fourth graders than the third grade SBA was for third graders</u>.” This threat to validity is called <strong>instrumentation</strong>.</p>
<p>“Of course their scores increased! <u>Students selected on the basis of extreme low scores will always score higher on average on the posttest because extreme low scores are extreme because of the combined effects of true achievement and measurement error</u>.” This threat to validity is called <strong>statistical regression</strong>.</p>
<p>Each of these is a threat to the <strong>internal validity</strong> of a program’s treatment. Internal validity is the “basic minimum without which any experiment is uninterpretable: Did in fact the experimental treatments make a difference in this specific experimental instance?” (<span class="citation" data-cites="CampbellStanley-1963">Campbell and Stanley (<a href="references.html#ref-CampbellStanley-1963" role="doc-biblioref">1963</a>)</span>, p.&nbsp;5)</p>
<p>Critics raise a couple of additional objections:</p>
<p>“These results are limited. <u>The students selected for the program were less impacted by poverty. They had more favorable demographics. They were different students</u>!” This treat to validity is called <strong>selection bias</strong>.</p>
<p>“These results are limited. <u>The students selected for the program were able to use their advantages to learn at a faster rate</u>.” This treat to validity is called <strong>selection-maturation interaction</strong>.</p>
<p>“These results are limited. <u>The students selected for the program were sensitive to the test. They knew they had scored below standard in the spring so they tried harder the next year</u>.” This threat to validity is called <strong>reactive</strong> or <strong>interaction effect of testing</strong>.&nbsp;</p>
<p>“These results are limited. <u>The students selected for the program had been low and received more attention and knew that we’re watching them closely</u>.” This threat to validity is called <strong>multiple-treatment interference</strong>.</p>
<p>These are threats to the <strong>external validity</strong> of a program’s treatment.&nbsp;External validity “asks the question of generalizability: To what populations, settings, treatment variables, and measurement variables can this effect be generalized?” Threats to external validity limit the generalizability of the results to broader populations.</p>
<p>What do you make of these objections, in light of the data and what you know of the design of the treatment? Are some more credible than others?</p>
</section>
<section id="experimental-design-with-random-assignment" class="level2">
<h2 class="anchored" data-anchor-id="experimental-design-with-random-assignment">Experimental design with random assignment</h2>
<p>The argument for the program is that it dramatically helps struggling readers, which is to say, struggling readers are <em>better off</em> in the program compared similar students in Tier 1 classroom instruction. This is because similar students did not gain as much as students in the program. The argument thus hinges on the similarity of the two groups. Any alternative explanation for the improvement of the experimental group must apply to the comparison group.</p>
<p>What if these students were assigned randomly to the conditions? This would have the effect of rendering pre-existing differences not statistically significant (that is, their differences were no more than we would expect to see by chance) … by design. This would strengthen the program advocates’ causal argument that (1) they were all the same students and (2) the program worked better than Tier 1 instruction.</p>
<p>Now it is probably wise to let go of it. Assuming we were so inclined, it is seldom feasible to prospectively randomly assign students to conditions, or to keep treatments so cleanly isolated, in real schools, districts, and dioceses. <strong>Nor will it be possible for you to fully design and carry out a prospective experimental design with random assignment in your current doctoral program</strong>.</p>
</section>
<section id="quasi-experimental-designs" class="level2">
<h2 class="anchored" data-anchor-id="quasi-experimental-designs">Quasi-experimental designs</h2>
<p>In lieu of a true experimental design, consider adding quasi-experimental designs to your toolbox. These are frameworks for collecting, organizing, and analyzing (primarily quantitative) data for causal inference – such as for program evaluation – that fall short of pure experimental design with random assignment, and therefore expose the evaluation to criticism. As Cox (in <span class="citation" data-cites="Burkholder">Burkholder et al. (<a href="references.html#ref-Burkholder" role="doc-biblioref">2020</a>)</span>, 56) puts it well: “The lack of random assignment in quasi-experimental designs means that the groups may not initially be equal or similar. This presents the challenge of ruling out other alternative explanations that could be responsible for any observed outcome.” Quasi-experimental designs use one or more work-arounds to mitigate various inescapable threats to validity. Consider three:</p>
<section id="the-nonequivalent-control-group-design" class="level3">
<h3 class="anchored" data-anchor-id="the-nonequivalent-control-group-design">The Nonequivalent Control Group Design</h3>
<p>This design comes from <span class="citation" data-cites="CampbellStanley-1963">Campbell and Stanley (<a href="references.html#ref-CampbellStanley-1963" role="doc-biblioref">1963</a>)</span>, who, at that time, claimed:</p>
<p>one of the most widespread experimental designs in educational research involves an experimental group and a control group both given a pretest and a posttest, but in which the control group and the experimental group do not have pre-experimental sampling equivalence. Rather, the groups constitute naturally assembled collectives such as classrooms, as similar as availability permits but yet not so similar that one can dispense with the pretest. (p.&nbsp;17)</p>
<p><span class="citation" data-cites="CookCampbell-1979">Cook and Campbell (<a href="references.html#ref-CookCampbell-1979" role="doc-biblioref">1979</a>)</span> later saw the design as “perhaps the most frequently used design in social science research and is fortunately often interpretable. It can, therefore, be recommended in situations where nothing better is available” (103-4).</p>
<p>Here is the design, and it is the design of the hypothetical example above:</p>
<table class="table">
<tbody>
<tr class="odd">
<td style="text-align: center;">O</td>
<td style="text-align: center;">X</td>
<td style="text-align: center;">O</td>
</tr>
<tr class="even">
<td style="text-align: center;">O</td>
<td style="text-align: center;"></td>
<td style="text-align: center;">O</td>
</tr>
</tbody>
</table>
<p>The design overcomes several of the critics’ objections raised above.</p>
<p>History, maturation, testing, and instrumentation are not credible objections because each of these explanations would apply to both groups, and the students in the experimental classroom still outperformed their peers in the comparison classroom. Notice here the added value of a comparison group!</p>
<p>Statistical regression is a valid criticism any time students are selected for a treatment on the basis of extreme scores, because extremely low or high pretest scores will always, on average, regress to mean. This should not be a problem if both groups were selected on the same set of extreme pretest scores.</p>
<p>Interactions between pretesting, selection, maturation, and the experimental treatment mean the students selected for the treatment were aware of their selection and reacted to it. This could be a valid threat whenever students selected for a program become aware of it, especially by virtue of contact with comparison students.</p>
</section>
</section>
<section id="how-to-do-a-program-evaluation-using-a-quasi-experimental-design" class="level2">
<h2 class="anchored" data-anchor-id="how-to-do-a-program-evaluation-using-a-quasi-experimental-design">How to do a program evaluation using a quasi-experimental design</h2>
<p>To carry out a retrospective analysis of existing quantitative data using quasi-experimental design for the purpose of program evaluation, you need:</p>
<ul>
<li><p>A group of schools/students/people who experienced some initiative, program, or treatment of interest</p></li>
<li><p>A comparison group of similar schools/students/people who did not experience the program or treatment of interest</p></li>
<li><p>Some pretest data, to establish baseline differences. Maybe these pretest data were the basis for assignment to the initiative or program</p></li>
<li><p>Some demographic data, to explore differences between the groups besides the treatment</p></li>
<li><p>Some posttest data, to establish outcomes of both groups. Ideally the pretest and posttest are the same interest, but this is not required.</p></li>
</ul>
<p>Concretely, all this means:</p>
<ul>
<li><p>Excel or other spreadsheet software, and in your worksheets you need:</p></li>
<li><p>A column of pretest scores on a population of schools or students</p></li>
<li><p>Columns for demographic variables on this population of schools or students (gender, race, low income, English language proficiency)</p></li>
<li><p>A column designating which schools or students participated in the initiative or program. Code the schoosl/students receiving the initiative/program as 1, all others 0.</p></li>
<li><p>A column of posttest scores on this population If these data are coming from different places then you need some kind of key variable (such as an ID number) that is common across all the different data sources which you can use to match the data together</p></li>
</ul>
<p>Your end game is one spreadsheet where all of these variables are together in one place. Then you can use PivotTable to summarize the data.&nbsp;<u>Keep checking back here for a sample Excel file as a guide</u>.</p>
</section>
<section id="recommended-further-reading" class="level2">
<h2 class="anchored" data-anchor-id="recommended-further-reading">Recommended further reading</h2>
<p>If your current or future work casts you in the role of program evaluator, it may help you to have some additional readings in your library for reference. Here are the three classic texts on experimental, quasi-experimental, and non-experimental design. I personally own and highly recommend all three.</p>
<p>Campbell, D. T., &amp; J. C. Stanley. 1963. Experimental and Quasi-Experimental Designs for Research. Houghton-Mifflin: Boston.</p>
<p>Cook, T.D., &amp; D.T. Campbell. 1979. Quasi-Experimentation: Design and Analysis Issues for Field Settings. Houghton Mifflin: Boston.</p>
<p>Shadish, W. R.., Cook, T. D., &amp; J.S. Campbell. 2002. Experimental and Quasi-Experimental Designs for Generalized Causal Inference. Houghton Mifflin: Boston.</p>
<hr>


<div id="refs" class="references csl-bib-body hanging-indent" role="doc-bibliography" style="display: none">
<div id="ref-Burkholder" class="csl-entry" role="doc-biblioentry">
Burkholder, G. J., K. A. Cox, L. M. Crawford, and Hitchcock. 2020. <em>Research Design and Methods: An Applied Guide for the Scholar-Practitioner</em>. Sage.
</div>
<div id="ref-CampbellStanley-1963" class="csl-entry" role="doc-biblioentry">
Campbell, D. T., and J. C. Stanley. 1963. <em>Experimental and Quasi-Experimental Designs for Research</em>. Houghton-Mifflin.
</div>
<div id="ref-CookCampbell-1979" class="csl-entry" role="doc-biblioentry">
Cook, T. D, and D. T. Campbell. 1979. <em>Quasi-Experimentation: Design and Analysis Issues for Field Settings</em>. Houghton-Mifflin.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./surveys.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Surveys</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>